#!/usr/bin/env ruby
# encoding: utf-8

# Query and answer questions based on an index file
#
# Usage: run-server config.json
#
# Requires OpenAI API Key stored in DOT_OPENAI_KEY

require "json"
require "ostruct"
require 'sinatra/base'

require_relative "../server/retriever"
require_relative "../server/synthesizer"
require_relative "../server/discuss"
require_relative "../server/duplicate"

if ARGV.length != 1
    STDOUT << "Invalid arguments received, need a config file\n"
    exit 1
end

config = JSON.parse(File.read(ARGV[0]))
CONFIG = OpenStruct.new(config)
CONFIG.paths = CONFIG.paths.map { |p| OpenStruct.new(p) }
CONFIG.paths.each { |p| p.searchDefault = !!p.searchDefault }
CONFIG.path_map = {}
CONFIG.paths.each { |p| CONFIG.path_map[p.name] = p }

OPENAI_KEY = ENV["DOT_OPENAI_KEY"] || ""
if OPENAI_KEY.empty?
    STDOUT << "Remember to set env DOT_OPENAI_KEY\n"
    exit 9
end

class SimpleRagServer < Sinatra::Application
    # list all the paths that can be searched
    get '/paths' do
        content_type :json

        resp = []
        CONFIG.paths.each do |p|
            resp << { name: p.name, searchDefault: p.searchDefault }
        end
        resp.to_json
    end

    # query within the paths
    post '/q' do
        content_type :json

        data = JSON.parse(request.body.read)

        selected = data["paths"]
        if !selected || selected.empty?
            selected = CONFIG.paths.select { |p| p.searchDefault }.map(&:name)
            selected = CONFIG.path_map.keys if selected.empty?
        end
        lookup_paths = selected.map { |name| CONFIG.path_map[name] }

        topN = (data["topN"] || 20).to_i

        q = data["q"]
        entries = retrieve_by_embedding(lookup_paths, q)
        if q.to_s.strip.length < 5 && q.to_s.split(/\s+/).length < 5
            entries.concat(retrieve_by_text(lookup_paths, q))

            unique = {}
            entries.each do |e|
                key = [e["path"], e["chunk"]]
                if unique[key]
                    unique[key]["score"] = (unique[key]["score"] || 0) + (e["score"] || 0)
                else
                    unique[key] = e
                end
            end

            entries = unique.values
        end
        entries = entries.sort_by { |item| -item["score"] }.take(topN)

        resp = {
            data: [],
        }

        entries.each do |item|
            resp[:data] << {
                path: item["path"],
                lookup: item["lookup"],
                id: item["id"],
                url: item["url"],
                text: item["reader"].load.get_chunk(item["chunk"]),
                score: item["score"],
            }
        end

        resp.to_json
    end

    # agentic query - expand the query using LLM before searching
    post '/q_plus' do
        content_type :json

        data = JSON.parse(request.body.read)

        selected = data["paths"]
        if !selected || selected.empty?
            selected = CONFIG.paths.select { |p| p.searchDefault }.map(&:name)
            selected = CONFIG.path_map.keys if selected.empty?
        end
        lookup_paths = selected.map { |name| CONFIG.path_map[name] }

        topN = (data["topN"] || 20).to_i

        expanded_q = expand_query(data["q"])
        variants = expand_variants(data["q"])

        entries = []
        entries.concat(retrieve_by_embedding(lookup_paths, data["q"]))
        entries.concat(retrieve_by_embedding(lookup_paths, expanded_q))
        variants.each { |v| entries.concat(retrieve_by_text(lookup_paths, v)) }

        unique = {}
        entries.each do |e|
            key = [e["path"], e["chunk"]]
            if unique[key]
                unique[key]["score"] = (unique[key]["score"] || 0) + (e["score"] || 0)
            else
                unique[key] = e
            end
        end

        ordered = unique.values.sort_by { |item| -item["score"] }.take(topN)

        resp = {
            data: [],
            expanded: expanded_q,
            variants: variants,
        }

        ordered.each do |item|
            resp[:data] << {
                path: item["path"],
                lookup: item["lookup"],
                id: item["id"],
                url: item["url"],
                text: item["reader"].load.get_chunk(item["chunk"]),
                score: item["score"],
            }
        end

        resp.to_json
    end

    # synthesize notes into a summary
    post '/synthesize' do
        content_type :json

        data = JSON.parse(request.body.read)

        summary = synthesize_notes(data["notes"])

        { note: summary }.to_json
    end

    # generate discussion for a single note
    post '/discuss' do
        content_type :json

        data = JSON.parse(request.body.read)

        discussion = discuss_note(data["note"])

        { discussion: discussion }.to_json
    end

    # find duplicate notes across selected paths
    post '/duplicates' do
        content_type :json

        data = JSON.parse(request.body.read)

        selected = data["paths"]
        threshold = (data["threshold"] || 0.9).to_f
        if !selected || selected.empty?
            selected = CONFIG.paths.map(&:name)
        end
        lookup_paths = selected.map { |name| CONFIG.path_map[name] }

        clusters = find_duplicates(lookup_paths, threshold)

        { clusters: clusters }.to_json
    end

    # return random notes from selected paths
    post '/random' do
        content_type :json

        data = JSON.parse(request.body.read)

        selected = data["paths"]
        count = (data["count"] || 3).to_i
        if !selected || selected.empty?
            selected = CONFIG.paths.map(&:name)
        end
        lookup_paths = selected.map { |name| CONFIG.path_map[name] }

        samples = []
        lookup_paths.each do |p|
            index = load_index_cache(p)
            next unless index
            reader_cls = index.reader_cls
            next unless reader_cls

            index.items.sample(count).each do |it|
                samples << {
                    path: p.name,
                    lookup: p.name,
                    id: extract_id(it[:path]),
                    url: extract_url(it[:path], p.url),
                    text: reader_cls.new(it[:path]).load.get_chunk(it[:chunk]),
                    score: 0,
                }
            end
        end

        samples = samples.sample(count)

        { data: samples }.to_json
    end

    # retrieve notes similar to provided note text
    post '/similar' do
        content_type :json

        data = JSON.parse(request.body.read)

        selected = data["paths"]
        topN = (data["topN"] || 3).to_i
        if !selected || selected.empty?
            selected = CONFIG.paths.map(&:name)
        end
        lookup_paths = selected.map { |name| CONFIG.path_map[name] }

        entries = retrieve_by_embedding(lookup_paths, data["note"] || "")
        entries = entries.sort_by { |item| -item["score"] }.take(topN)

        resp = { data: [] }
        entries.each do |item|
            resp[:data] << {
                path: item["path"],
                lookup: item["lookup"],
                id: item["id"],
                url: item["url"],
                text: item["reader"].load.get_chunk(item["chunk"]),
                score: item["score"],
            }
        end

        resp.to_json
    end
end

SimpleRagServer.run!
